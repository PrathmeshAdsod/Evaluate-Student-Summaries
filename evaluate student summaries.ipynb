{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Goal\n\n<h3 style=\"color:blue\">assess the quality of summaries written by students</h3>\n<h3 style=\"color:indigo\">evaluate how well a student represents the main idea and details of a source text, as well as the clarity, precision, and fluency of the language used in the summary</h3>\n<h3 style=\"color:red\">Freely & publicly available external data is <b>allowed</b>, including pre-trained models</h3>\n<h3>This is Multi-Output problem</h3>","metadata":{}},{"cell_type":"markdown","source":"### Use Hugging Face Library\n### Use NLTK\n### Use Tensorflow","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:56:48.665625Z","iopub.execute_input":"2023-08-26T08:56:48.665985Z","iopub.status.idle":"2023-08-26T08:56:48.677822Z","shell.execute_reply.started":"2023-08-26T08:56:48.665954Z","shell.execute_reply":"2023-08-26T08:56:48.676521Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport math\nimport subprocess\nfrom tqdm import tqdm\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:56:48.698087Z","iopub.execute_input":"2023-08-26T08:56:48.698488Z","iopub.status.idle":"2023-08-26T08:56:49.482032Z","shell.execute_reply.started":"2023-08-26T08:56:48.698451Z","shell.execute_reply":"2023-08-26T08:56:49.481055Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:56:49.483835Z","iopub.execute_input":"2023-08-26T08:56:49.484178Z","iopub.status.idle":"2023-08-26T08:56:58.828267Z","shell.execute_reply.started":"2023-08-26T08:56:49.484146Z","shell.execute_reply":"2023-08-26T08:56:58.827240Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score, median_absolute_error","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:56:58.833932Z","iopub.execute_input":"2023-08-26T08:56:58.840450Z","iopub.status.idle":"2023-08-26T08:56:59.015131Z","shell.execute_reply.started":"2023-08-26T08:56:58.840407Z","shell.execute_reply":"2023-08-26T08:56:59.014043Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer, TFBertModel","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:56:59.018030Z","iopub.execute_input":"2023-08-26T08:56:59.018691Z","iopub.status.idle":"2023-08-26T08:57:02.905832Z","shell.execute_reply.started":"2023-08-26T08:56:59.018653Z","shell.execute_reply":"2023-08-26T08:57:02.904835Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import keras_tuner ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:02.907275Z","iopub.execute_input":"2023-08-26T08:57:02.908014Z","iopub.status.idle":"2023-08-26T08:57:03.321628Z","shell.execute_reply.started":"2023-08-26T08:57:02.907979Z","shell.execute_reply":"2023-08-26T08:57:03.320604Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nsummaries_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\nprompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\nsummaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.325058Z","iopub.execute_input":"2023-08-26T08:57:03.326478Z","iopub.status.idle":"2023-08-26T08:57:03.473966Z","shell.execute_reply.started":"2023-08-26T08:57:03.326441Z","shell.execute_reply":"2023-08-26T08:57:03.472878Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train, summaries_train, on='prompt_id')\ntest = pd.merge(prompts_test, summaries_test, on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.477813Z","iopub.execute_input":"2023-08-26T08:57:03.478111Z","iopub.status.idle":"2023-08-26T08:57:03.504304Z","shell.execute_reply.started":"2023-08-26T08:57:03.478086Z","shell.execute_reply":"2023-08-26T08:57:03.503384Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train.rename(columns = {'text' : 'summary'}, inplace=True)\ntest.rename(columns = {'text' : 'summary'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.505643Z","iopub.execute_input":"2023-08-26T08:57:03.506067Z","iopub.status.idle":"2023-08-26T08:57:03.513297Z","shell.execute_reply.started":"2023-08-26T08:57:03.506033Z","shell.execute_reply":"2023-08-26T08:57:03.512296Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.514873Z","iopub.execute_input":"2023-08-26T08:57:03.515834Z","iopub.status.idle":"2023-08-26T08:57:03.536162Z","shell.execute_reply.started":"2023-08-26T08:57:03.515803Z","shell.execute_reply":"2023-08-26T08:57:03.535226Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n\n                                             summary   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>summary</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0086ef22de8f</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n      <td>-0.970237</td>\n      <td>-0.417058</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['summary'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.540659Z","iopub.execute_input":"2023-08-26T08:57:03.540913Z","iopub.status.idle":"2023-08-26T08:57:03.547556Z","shell.execute_reply.started":"2023-08-26T08:57:03.540890Z","shell.execute_reply":"2023-08-26T08:57:03.546643Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"},"metadata":{}}]},{"cell_type":"code","source":"columns_needed = [\"prompt_text\", \"summary\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.549032Z","iopub.execute_input":"2023-08-26T08:57:03.549675Z","iopub.status.idle":"2023-08-26T08:57:03.557260Z","shell.execute_reply.started":"2023-08-26T08:57:03.549643Z","shell.execute_reply":"2023-08-26T08:57:03.556429Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data = train[columns_needed]\ntest_data = test[columns_needed]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.558771Z","iopub.execute_input":"2023-08-26T08:57:03.559126Z","iopub.status.idle":"2023-08-26T08:57:03.571979Z","shell.execute_reply.started":"2023-08-26T08:57:03.559095Z","shell.execute_reply":"2023-08-26T08:57:03.571020Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#from transformers import XLNetTokenizer, TFXLNetModel\n#tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n#model = TFXLNetModel.from_pretrained('xlnet-base-cased', return_dict=True)\n\n#from transformers import RobertaTokenizer, TFRobertaModel\n#tokenizer = RobertaTokenizer.from_pretrained('roberta-base-cased')\n#model = TFRobertaModel.from_pretrained('roberta-base-cased', return_dict=True)\n\nfrom transformers import AutoTokenizer, TFBertModel\nmodel = TFBertModel.from_pretrained('/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased')\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:03.575131Z","iopub.execute_input":"2023-08-26T08:57:03.575546Z","iopub.status.idle":"2023-08-26T08:57:17.310009Z","shell.execute_reply.started":"2023-08-26T08:57:03.575514Z","shell.execute_reply":"2023-08-26T08:57:17.309010Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at /kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at /kaggle/input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Next time use prepare_tf_dataset which is used to directly tokenize and data colat and\n### make dataset compatible with tensorflow\n####       https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset","metadata":{}},{"cell_type":"code","source":"\ndef vectorize_dataframe(dataframe, col):\n    vectors = []\n    for text in tqdm(dataframe[col].tolist()):\n        text_tokens = tokenizer(text, return_tensors=\"tf\",max_length = 512, padding='max_length', truncation=True)\n        \n        output = model(text_tokens)\n        \n        pooler_output = output.pooler_output\n\n        vectors.append(pooler_output)\n    return vectors\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:17.311479Z","iopub.execute_input":"2023-08-26T08:57:17.311931Z","iopub.status.idle":"2023-08-26T08:57:17.319767Z","shell.execute_reply.started":"2023-08-26T08:57:17.311895Z","shell.execute_reply":"2023-08-26T08:57:17.317664Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_data['prompt_text_embedded'] = vectorize_dataframe(test_data, 'prompt_text')\ntest_data['summary_embedded'] = vectorize_dataframe(test_data, 'summary')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:17.321146Z","iopub.execute_input":"2023-08-26T08:57:17.321851Z","iopub.status.idle":"2023-08-26T08:57:18.903249Z","shell.execute_reply.started":"2023-08-26T08:57:17.321819Z","shell.execute_reply":"2023-08-26T08:57:18.902339Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 4/4 [00:00<00:00,  4.90it/s]\n100%|██████████| 4/4 [00:00<00:00,  5.44it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(\"/kaggle/input/embeddings/BERT_prompt_text_embeddings.pkl\", \"rb\") as file:\n    train_data['prompt_text_embedded'] = pickle.load(file)\n    \nwith open(\"/kaggle/input/embeddings/BERT_summary_embeddings.pkl\", \"rb\") as file:\n    train_data['summary_embedded'] = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:18.904897Z","iopub.execute_input":"2023-08-26T08:57:18.905251Z","iopub.status.idle":"2023-08-26T08:57:21.983051Z","shell.execute_reply.started":"2023-08-26T08:57:18.905218Z","shell.execute_reply":"2023-08-26T08:57:21.982061Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"traning_set = train_data[['prompt_text_embedded', 'summary_embedded']]\ntesting_set = test_data[['prompt_text_embedded', 'summary_embedded']]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:21.984498Z","iopub.execute_input":"2023-08-26T08:57:21.984847Z","iopub.status.idle":"2023-08-26T08:57:21.996463Z","shell.execute_reply.started":"2023-08-26T08:57:21.984816Z","shell.execute_reply":"2023-08-26T08:57:21.995529Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Take average of embeddings  [Not required, just checking]","metadata":{}},{"cell_type":"code","source":"target1 = np.array(train['content'])\ntarget1 = target1.astype('float32')\n\ntarget2 = np.array(train['wording'])\ntarget2 = target2.astype('float32')\n\n#target = (target1, target2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:21.997760Z","iopub.execute_input":"2023-08-26T08:57:21.998404Z","iopub.status.idle":"2023-08-26T08:57:22.010104Z","shell.execute_reply.started":"2023-08-26T08:57:21.998369Z","shell.execute_reply":"2023-08-26T08:57:22.009064Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def convert_tensor_to_numpy(tensor):\n        return np.array(tensor, dtype='float32')\n\ntraning_set = traning_set.applymap(convert_tensor_to_numpy)\ntesting_set = testing_set.applymap(convert_tensor_to_numpy)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.011608Z","iopub.execute_input":"2023-08-26T08:57:22.012010Z","iopub.status.idle":"2023-08-26T08:57:22.579550Z","shell.execute_reply.started":"2023-08-26T08:57:22.011975Z","shell.execute_reply":"2023-08-26T08:57:22.578556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(dataset):\n    # Flatten the nested arrays in the DataFrame\n    dataset['prompt_text_embedded'] = dataset['prompt_text_embedded'].apply(lambda x: x.flatten())\n    dataset['summary_embedded'] = dataset['summary_embedded'].apply(lambda x: x.flatten())\n    \n    feature1 = np.array(dataset['prompt_text_embedded'].tolist())\n    feature2 = np.array(dataset['summary_embedded'].tolist())\n    \n    features = np.concatenate((feature1, feature2), axis=1)\n    \n    return features","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.580769Z","iopub.execute_input":"2023-08-26T08:57:22.581113Z","iopub.status.idle":"2023-08-26T08:57:22.589395Z","shell.execute_reply.started":"2023-08-26T08:57:22.581082Z","shell.execute_reply":"2023-08-26T08:57:22.587053Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"features = prepare_dataset(traning_set)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.591148Z","iopub.execute_input":"2023-08-26T08:57:22.591876Z","iopub.status.idle":"2023-08-26T08:57:22.680974Z","shell.execute_reply.started":"2023-08-26T08:57:22.591835Z","shell.execute_reply":"2023-08-26T08:57:22.679979Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"features_for_test = prepare_dataset(testing_set)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.682541Z","iopub.execute_input":"2023-08-26T08:57:22.683001Z","iopub.status.idle":"2023-08-26T08:57:22.689585Z","shell.execute_reply.started":"2023-08-26T08:57:22.682954Z","shell.execute_reply":"2023-08-26T08:57:22.688536Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Input, Flatten","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.690896Z","iopub.execute_input":"2023-08-26T08:57:22.691653Z","iopub.status.idle":"2023-08-26T08:57:22.702398Z","shell.execute_reply.started":"2023-08-26T08:57:22.691619Z","shell.execute_reply":"2023-08-26T08:57:22.701444Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def build_model_content(hp):   \n   \n    #optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n    \n    model_content = tf.keras.Sequential([\n            Dense( units=hp.Int(\"units1\", min_value=252, max_value=356, step=32)),\n            Dense( units=hp.Int(\"units2\", min_value=156, max_value=252, step=32)),\n            Dense( units=hp.Int(\"units3\", min_value=48, max_value=156, step=32)),\n            Dense(1, activation='linear')\n    ])\n    \n    model_content.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae', 'mse'])\n    \n    return model_content\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.704072Z","iopub.execute_input":"2023-08-26T08:57:22.704874Z","iopub.status.idle":"2023-08-26T08:57:22.714285Z","shell.execute_reply.started":"2023-08-26T08:57:22.704842Z","shell.execute_reply":"2023-08-26T08:57:22.713193Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def build_model_wording(hp):   \n   \n    #optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n    \n    model_wording = tf.keras.Sequential([\n            Dense( units=hp.Int(\"units1\", min_value=252, max_value=356, step=32)),\n            Dense( units=hp.Int(\"units2\", min_value=156, max_value=252, step=32)),\n            Dense( units=hp.Int(\"units3\", min_value=48, max_value=156, step=32)),\n            Dense(1, activation='linear')\n    ])\n    \n    model_wording.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae', 'mse'])\n    \n    return model_wording","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.715734Z","iopub.execute_input":"2023-08-26T08:57:22.716211Z","iopub.status.idle":"2023-08-26T08:57:22.727274Z","shell.execute_reply.started":"2023-08-26T08:57:22.716179Z","shell.execute_reply":"2023-08-26T08:57:22.726342Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### hyperband for build_model_content","metadata":{}},{"cell_type":"code","source":"\nobjective = keras_tuner.Objective('mse', 'min')\n\ncontent_tuner = keras_tuner.Hyperband(\n    hypermodel=build_model_content,\n    objective=objective,\n    max_epochs=20,\n    factor=3,\n    hyperband_iterations=3,\n    tune_new_entries=True,\n    allow_new_entries=True,\n    max_retries_per_trial=5,\n    max_consecutive_failed_trials=5\n)\n\nwording_tuner = keras_tuner.Hyperband(\n    hypermodel=build_model_wording,\n    objective=objective,\n    max_epochs=20,\n    factor=3,\n    hyperband_iterations=3,\n    tune_new_entries=True,\n    allow_new_entries=True,\n    max_retries_per_trial=5,\n    max_consecutive_failed_trials=5\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.728552Z","iopub.execute_input":"2023-08-26T08:57:22.729085Z","iopub.status.idle":"2023-08-26T08:57:22.781362Z","shell.execute_reply.started":"2023-08-26T08:57:22.729052Z","shell.execute_reply":"2023-08-26T08:57:22.780467Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"content_tuner.search(features, target1,epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T08:57:22.784209Z","iopub.execute_input":"2023-08-26T08:57:22.784554Z","iopub.status.idle":"2023-08-26T09:09:57.619384Z","shell.execute_reply.started":"2023-08-26T08:57:22.784527Z","shell.execute_reply":"2023-08-26T09:09:57.618127Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Trial 81 Complete [00h 00m 08s]\nmse: 0.36659523844718933\n\nBest mse So Far: 0.3224892020225525\nTotal elapsed time: 00h 12m 35s\n","output_type":"stream"}]},{"cell_type":"code","source":"wording_tuner.search(features, target2,epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:09:57.625561Z","iopub.execute_input":"2023-08-26T09:09:57.625866Z","iopub.status.idle":"2023-08-26T09:22:18.638678Z","shell.execute_reply.started":"2023-08-26T09:09:57.625839Z","shell.execute_reply":"2023-08-26T09:22:18.637225Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Trial 79 Complete [00h 00m 11s]\nmse: 0.5533625483512878\n\nBest mse So Far: 0.5006468892097473\nTotal elapsed time: 00h 12m 21s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_content_tuner_hps=content_tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# Get the optimal hyperparameters\nbest_wording_tuner_hps=wording_tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:22:18.640000Z","iopub.execute_input":"2023-08-26T09:22:18.640383Z","iopub.status.idle":"2023-08-26T09:22:18.646550Z","shell.execute_reply.started":"2023-08-26T09:22:18.640342Z","shell.execute_reply":"2023-08-26T09:22:18.645262Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"best_content_tuner_hps.values","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:22:18.648218Z","iopub.execute_input":"2023-08-26T09:22:18.648619Z","iopub.status.idle":"2023-08-26T09:22:18.661347Z","shell.execute_reply.started":"2023-08-26T09:22:18.648585Z","shell.execute_reply":"2023-08-26T09:22:18.660443Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'units1': 284,\n 'units2': 220,\n 'units3': 48,\n 'tuner/epochs': 20,\n 'tuner/initial_epoch': 7,\n 'tuner/bracket': 2,\n 'tuner/round': 2,\n 'tuner/trial_id': '0013'}"},"metadata":{}}]},{"cell_type":"code","source":"best_wording_tuner_hps.values","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:22:18.664572Z","iopub.execute_input":"2023-08-26T09:22:18.664879Z","iopub.status.idle":"2023-08-26T09:22:18.674028Z","shell.execute_reply.started":"2023-08-26T09:22:18.664844Z","shell.execute_reply":"2023-08-26T09:22:18.672914Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'units1': 316,\n 'units2': 156,\n 'units3': 112,\n 'tuner/epochs': 20,\n 'tuner/initial_epoch': 7,\n 'tuner/bracket': 2,\n 'tuner/round': 2,\n 'tuner/trial_id': '0013'}"},"metadata":{}}]},{"cell_type":"code","source":"content_hp_model = content_tuner.hypermodel.build(best_content_tuner_hps)\nhistory__1 = content_hp_model.fit(features, target1, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:29:16.139412Z","iopub.execute_input":"2023-08-26T09:29:16.139795Z","iopub.status.idle":"2023-08-26T09:30:35.450373Z","shell.execute_reply.started":"2023-08-26T09:29:16.139766Z","shell.execute_reply":"2023-08-26T09:30:35.449499Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/100\n224/224 [==============================] - 2s 3ms/step - loss: 0.6036 - mae: 0.5904 - mse: 0.6036\nEpoch 2/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.4253 - mae: 0.5060 - mse: 0.4253\nEpoch 3/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.4049 - mae: 0.4922 - mse: 0.4049\nEpoch 4/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3987 - mae: 0.4905 - mse: 0.3987\nEpoch 5/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3883 - mae: 0.4854 - mse: 0.3883\nEpoch 6/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3723 - mae: 0.4757 - mse: 0.3723\nEpoch 7/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3665 - mae: 0.4713 - mse: 0.3665\nEpoch 8/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3573 - mae: 0.4631 - mse: 0.3573\nEpoch 9/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3595 - mae: 0.4633 - mse: 0.3595\nEpoch 10/100\n224/224 [==============================] - 1s 5ms/step - loss: 0.3405 - mae: 0.4528 - mse: 0.3405\nEpoch 11/100\n224/224 [==============================] - 1s 5ms/step - loss: 0.3467 - mae: 0.4557 - mse: 0.3467\nEpoch 12/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3340 - mae: 0.4489 - mse: 0.3340\nEpoch 13/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3351 - mae: 0.4476 - mse: 0.3351\nEpoch 14/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3469 - mae: 0.4563 - mse: 0.3469\nEpoch 15/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3289 - mae: 0.4439 - mse: 0.3289\nEpoch 16/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3286 - mae: 0.4424 - mse: 0.3286\nEpoch 17/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3273 - mae: 0.4449 - mse: 0.3273\nEpoch 18/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3352 - mae: 0.4483 - mse: 0.3352\nEpoch 19/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3219 - mae: 0.4405 - mse: 0.3219\nEpoch 20/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3247 - mae: 0.4423 - mse: 0.3247\nEpoch 21/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3237 - mae: 0.4395 - mse: 0.3237\nEpoch 22/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3242 - mae: 0.4427 - mse: 0.3242\nEpoch 23/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3141 - mae: 0.4346 - mse: 0.3141\nEpoch 24/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3308 - mae: 0.4443 - mse: 0.3308\nEpoch 25/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3088 - mae: 0.4301 - mse: 0.3088\nEpoch 26/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3158 - mae: 0.4335 - mse: 0.3158\nEpoch 27/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3191 - mae: 0.4386 - mse: 0.3191\nEpoch 28/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3133 - mae: 0.4325 - mse: 0.3133\nEpoch 29/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3046 - mae: 0.4271 - mse: 0.3046\nEpoch 30/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3123 - mae: 0.4334 - mse: 0.3123\nEpoch 31/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3128 - mae: 0.4337 - mse: 0.3128\nEpoch 32/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3150 - mae: 0.4348 - mse: 0.3150\nEpoch 33/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3031 - mae: 0.4254 - mse: 0.3031\nEpoch 34/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3122 - mae: 0.4317 - mse: 0.3122\nEpoch 35/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3037 - mae: 0.4254 - mse: 0.3037\nEpoch 36/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3007 - mae: 0.4257 - mse: 0.3007\nEpoch 37/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3171 - mae: 0.4355 - mse: 0.3171\nEpoch 38/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2975 - mae: 0.4229 - mse: 0.2975\nEpoch 39/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3092 - mae: 0.4301 - mse: 0.3092\nEpoch 40/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3044 - mae: 0.4275 - mse: 0.3044\nEpoch 41/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.3098 - mae: 0.4321 - mse: 0.3098\nEpoch 42/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2989 - mae: 0.4217 - mse: 0.2989\nEpoch 43/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3011 - mae: 0.4245 - mse: 0.3011\nEpoch 44/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3001 - mae: 0.4244 - mse: 0.3001\nEpoch 45/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3039 - mae: 0.4260 - mse: 0.3039\nEpoch 46/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2915 - mae: 0.4178 - mse: 0.2915\nEpoch 47/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2895 - mae: 0.4164 - mse: 0.2895\nEpoch 48/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.3016 - mae: 0.4245 - mse: 0.3016\nEpoch 49/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2959 - mae: 0.4214 - mse: 0.2959\nEpoch 50/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2950 - mae: 0.4214 - mse: 0.2950\nEpoch 51/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2896 - mae: 0.4170 - mse: 0.2896\nEpoch 52/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2904 - mae: 0.4162 - mse: 0.2904\nEpoch 53/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2888 - mae: 0.4163 - mse: 0.2888\nEpoch 54/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2974 - mae: 0.4220 - mse: 0.2974\nEpoch 55/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2895 - mae: 0.4163 - mse: 0.2895\nEpoch 56/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2956 - mae: 0.4222 - mse: 0.2956\nEpoch 57/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2883 - mae: 0.4152 - mse: 0.2883\nEpoch 58/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2856 - mae: 0.4124 - mse: 0.2856\nEpoch 59/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2959 - mae: 0.4194 - mse: 0.2959\nEpoch 60/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2903 - mae: 0.4164 - mse: 0.2903\nEpoch 61/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2841 - mae: 0.4111 - mse: 0.2841\nEpoch 62/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2829 - mae: 0.4112 - mse: 0.2829\nEpoch 63/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2831 - mae: 0.4110 - mse: 0.2831\nEpoch 64/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2843 - mae: 0.4116 - mse: 0.2843\nEpoch 65/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2799 - mae: 0.4089 - mse: 0.2799\nEpoch 66/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2875 - mae: 0.4142 - mse: 0.2875\nEpoch 67/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2819 - mae: 0.4097 - mse: 0.2819\nEpoch 68/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2893 - mae: 0.4152 - mse: 0.2893\nEpoch 69/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2969 - mae: 0.4230 - mse: 0.2969\nEpoch 70/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2844 - mae: 0.4124 - mse: 0.2844\nEpoch 71/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2868 - mae: 0.4147 - mse: 0.2868\nEpoch 72/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2860 - mae: 0.4128 - mse: 0.2860\nEpoch 73/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2820 - mae: 0.4102 - mse: 0.2820\nEpoch 74/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2832 - mae: 0.4109 - mse: 0.2832\nEpoch 75/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2851 - mae: 0.4131 - mse: 0.2851\nEpoch 76/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2780 - mae: 0.4068 - mse: 0.2780\nEpoch 77/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2822 - mae: 0.4116 - mse: 0.2822\nEpoch 78/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2806 - mae: 0.4088 - mse: 0.2806\nEpoch 79/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2884 - mae: 0.4141 - mse: 0.2884\nEpoch 80/100\n224/224 [==============================] - 1s 4ms/step - loss: 0.2854 - mae: 0.4133 - mse: 0.2854\nEpoch 81/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2833 - mae: 0.4098 - mse: 0.2833\nEpoch 82/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2866 - mae: 0.4146 - mse: 0.2866\nEpoch 83/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2801 - mae: 0.4093 - mse: 0.2801\nEpoch 84/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2847 - mae: 0.4150 - mse: 0.2847\nEpoch 85/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2733 - mae: 0.4026 - mse: 0.2733\nEpoch 86/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2772 - mae: 0.4082 - mse: 0.2772\nEpoch 87/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2849 - mae: 0.4134 - mse: 0.2849\nEpoch 88/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2773 - mae: 0.4075 - mse: 0.2773\nEpoch 89/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2788 - mae: 0.4083 - mse: 0.2788\nEpoch 90/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2785 - mae: 0.4075 - mse: 0.2785\nEpoch 91/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2839 - mae: 0.4124 - mse: 0.2839\nEpoch 92/100\n224/224 [==============================] - 1s 5ms/step - loss: 0.2780 - mae: 0.4070 - mse: 0.2780\nEpoch 93/100\n224/224 [==============================] - 1s 5ms/step - loss: 0.2858 - mae: 0.4149 - mse: 0.2858\nEpoch 94/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2681 - mae: 0.3996 - mse: 0.2681\nEpoch 95/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2914 - mae: 0.4188 - mse: 0.2914\nEpoch 96/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2785 - mae: 0.4072 - mse: 0.2785\nEpoch 97/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2761 - mae: 0.4058 - mse: 0.2761\nEpoch 98/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2739 - mae: 0.4050 - mse: 0.2739\nEpoch 99/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2711 - mae: 0.4027 - mse: 0.2711\nEpoch 100/100\n224/224 [==============================] - 1s 3ms/step - loss: 0.2662 - mae: 0.3976 - mse: 0.2662\n","output_type":"stream"}]},{"cell_type":"code","source":"wording_hp_model = wording_tuner.hypermodel.build(best_wording_tuner_hps)\nhistory__2 = wording_hp_model.fit(features, target2, epochs=150)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:30:35.452577Z","iopub.execute_input":"2023-08-26T09:30:35.452951Z","iopub.status.idle":"2023-08-26T09:32:58.206227Z","shell.execute_reply.started":"2023-08-26T09:30:35.452915Z","shell.execute_reply":"2023-08-26T09:32:58.205174Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/150\n224/224 [==============================] - 2s 4ms/step - loss: 0.7180 - mae: 0.6642 - mse: 0.7180\nEpoch 2/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.6199 - mae: 0.6184 - mse: 0.6199\nEpoch 3/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.5984 - mae: 0.6048 - mse: 0.5984\nEpoch 4/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5519 - mae: 0.5802 - mse: 0.5519\nEpoch 5/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5457 - mae: 0.5789 - mse: 0.5457\nEpoch 6/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5460 - mae: 0.5778 - mse: 0.5460\nEpoch 7/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5403 - mae: 0.5752 - mse: 0.5403\nEpoch 8/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5227 - mae: 0.5653 - mse: 0.5227\nEpoch 9/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5138 - mae: 0.5605 - mse: 0.5138\nEpoch 10/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5204 - mae: 0.5636 - mse: 0.5204\nEpoch 11/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5038 - mae: 0.5542 - mse: 0.5038\nEpoch 12/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5119 - mae: 0.5591 - mse: 0.5119\nEpoch 13/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5222 - mae: 0.5661 - mse: 0.5222\nEpoch 14/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5105 - mae: 0.5580 - mse: 0.5105\nEpoch 15/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5052 - mae: 0.5561 - mse: 0.5052\nEpoch 16/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.5054 - mae: 0.5562 - mse: 0.5054\nEpoch 17/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4873 - mae: 0.5462 - mse: 0.4873\nEpoch 18/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4810 - mae: 0.5406 - mse: 0.4810\nEpoch 19/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.5053 - mae: 0.5547 - mse: 0.5053\nEpoch 20/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4953 - mae: 0.5498 - mse: 0.4953\nEpoch 21/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4901 - mae: 0.5465 - mse: 0.4901\nEpoch 22/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4752 - mae: 0.5391 - mse: 0.4752\nEpoch 23/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4821 - mae: 0.5413 - mse: 0.4821\nEpoch 24/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4854 - mae: 0.5431 - mse: 0.4854\nEpoch 25/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4785 - mae: 0.5402 - mse: 0.4785\nEpoch 26/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4770 - mae: 0.5405 - mse: 0.4770\nEpoch 27/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4875 - mae: 0.5451 - mse: 0.4875\nEpoch 28/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4743 - mae: 0.5381 - mse: 0.4743\nEpoch 29/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4839 - mae: 0.5439 - mse: 0.4839\nEpoch 30/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4828 - mae: 0.5421 - mse: 0.4828\nEpoch 31/150\n224/224 [==============================] - 1s 5ms/step - loss: 0.4736 - mae: 0.5386 - mse: 0.4736\nEpoch 32/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4761 - mae: 0.5394 - mse: 0.4761\nEpoch 33/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4763 - mae: 0.5401 - mse: 0.4763\nEpoch 34/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4664 - mae: 0.5353 - mse: 0.4664\nEpoch 35/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4656 - mae: 0.5313 - mse: 0.4656\nEpoch 36/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4689 - mae: 0.5361 - mse: 0.4689\nEpoch 37/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4573 - mae: 0.5273 - mse: 0.4573\nEpoch 38/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4607 - mae: 0.5294 - mse: 0.4607\nEpoch 39/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4682 - mae: 0.5340 - mse: 0.4682\nEpoch 40/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4656 - mae: 0.5342 - mse: 0.4656\nEpoch 41/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4572 - mae: 0.5281 - mse: 0.4572\nEpoch 42/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4665 - mae: 0.5336 - mse: 0.4665\nEpoch 43/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4520 - mae: 0.5247 - mse: 0.4520\nEpoch 44/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4660 - mae: 0.5364 - mse: 0.4660\nEpoch 45/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4542 - mae: 0.5255 - mse: 0.4542\nEpoch 46/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4530 - mae: 0.5242 - mse: 0.4530\nEpoch 47/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4523 - mae: 0.5248 - mse: 0.4523\nEpoch 48/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4550 - mae: 0.5260 - mse: 0.4550\nEpoch 49/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4460 - mae: 0.5211 - mse: 0.4460\nEpoch 50/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4555 - mae: 0.5278 - mse: 0.4555\nEpoch 51/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4501 - mae: 0.5244 - mse: 0.4501\nEpoch 52/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4497 - mae: 0.5259 - mse: 0.4497\nEpoch 53/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4562 - mae: 0.5284 - mse: 0.4562\nEpoch 54/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4535 - mae: 0.5243 - mse: 0.4535\nEpoch 55/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4559 - mae: 0.5275 - mse: 0.4559\nEpoch 56/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4542 - mae: 0.5257 - mse: 0.4542\nEpoch 57/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4471 - mae: 0.5208 - mse: 0.4471\nEpoch 58/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4532 - mae: 0.5249 - mse: 0.4532\nEpoch 59/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4601 - mae: 0.5292 - mse: 0.4601\nEpoch 60/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4396 - mae: 0.5170 - mse: 0.4396\nEpoch 61/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4445 - mae: 0.5217 - mse: 0.4445\nEpoch 62/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4470 - mae: 0.5222 - mse: 0.4470\nEpoch 63/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4556 - mae: 0.5292 - mse: 0.4556\nEpoch 64/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4487 - mae: 0.5223 - mse: 0.4487\nEpoch 65/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4571 - mae: 0.5272 - mse: 0.4571\nEpoch 66/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4420 - mae: 0.5189 - mse: 0.4420\nEpoch 67/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4435 - mae: 0.5208 - mse: 0.4435\nEpoch 68/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4432 - mae: 0.5193 - mse: 0.4432\nEpoch 69/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4421 - mae: 0.5181 - mse: 0.4421\nEpoch 70/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4479 - mae: 0.5229 - mse: 0.4479\nEpoch 71/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4472 - mae: 0.5209 - mse: 0.4472\nEpoch 72/150\n224/224 [==============================] - 1s 5ms/step - loss: 0.4428 - mae: 0.5209 - mse: 0.4428\nEpoch 73/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4311 - mae: 0.5118 - mse: 0.4311\nEpoch 74/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4525 - mae: 0.5251 - mse: 0.4525\nEpoch 75/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4348 - mae: 0.5155 - mse: 0.4348\nEpoch 76/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4418 - mae: 0.5212 - mse: 0.4418\nEpoch 77/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4349 - mae: 0.5156 - mse: 0.4349\nEpoch 78/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4378 - mae: 0.5167 - mse: 0.4378\nEpoch 79/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4451 - mae: 0.5205 - mse: 0.4451\nEpoch 80/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4340 - mae: 0.5144 - mse: 0.4340\nEpoch 81/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4425 - mae: 0.5187 - mse: 0.4425\nEpoch 82/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4541 - mae: 0.5267 - mse: 0.4541\nEpoch 83/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4548 - mae: 0.5249 - mse: 0.4548\nEpoch 84/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4393 - mae: 0.5164 - mse: 0.4393\nEpoch 85/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4369 - mae: 0.5159 - mse: 0.4369\nEpoch 86/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4309 - mae: 0.5115 - mse: 0.4309\nEpoch 87/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4371 - mae: 0.5154 - mse: 0.4371\nEpoch 88/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4406 - mae: 0.5189 - mse: 0.4406\nEpoch 89/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4323 - mae: 0.5139 - mse: 0.4323\nEpoch 90/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4511 - mae: 0.5243 - mse: 0.4511\nEpoch 91/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4404 - mae: 0.5183 - mse: 0.4404\nEpoch 92/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4379 - mae: 0.5164 - mse: 0.4379\nEpoch 93/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4400 - mae: 0.5173 - mse: 0.4400\nEpoch 94/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4330 - mae: 0.5145 - mse: 0.4330\nEpoch 95/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4288 - mae: 0.5114 - mse: 0.4288\nEpoch 96/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4367 - mae: 0.5167 - mse: 0.4367\nEpoch 97/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4406 - mae: 0.5190 - mse: 0.4406\nEpoch 98/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4249 - mae: 0.5091 - mse: 0.4249\nEpoch 99/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4330 - mae: 0.5133 - mse: 0.4330\nEpoch 100/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4355 - mae: 0.5163 - mse: 0.4355\nEpoch 101/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4301 - mae: 0.5126 - mse: 0.4301\nEpoch 102/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4434 - mae: 0.5192 - mse: 0.4434\nEpoch 103/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4361 - mae: 0.5163 - mse: 0.4361\nEpoch 104/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4275 - mae: 0.5097 - mse: 0.4275\nEpoch 105/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4430 - mae: 0.5216 - mse: 0.4430\nEpoch 106/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4302 - mae: 0.5125 - mse: 0.4302\nEpoch 107/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4360 - mae: 0.5170 - mse: 0.4360\nEpoch 108/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4276 - mae: 0.5089 - mse: 0.4276\nEpoch 109/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4342 - mae: 0.5137 - mse: 0.4342\nEpoch 110/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4373 - mae: 0.5149 - mse: 0.4373\nEpoch 111/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4318 - mae: 0.5152 - mse: 0.4318\nEpoch 112/150\n224/224 [==============================] - 1s 5ms/step - loss: 0.4348 - mae: 0.5157 - mse: 0.4348\nEpoch 113/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4348 - mae: 0.5150 - mse: 0.4348\nEpoch 114/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4265 - mae: 0.5092 - mse: 0.4265\nEpoch 115/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4218 - mae: 0.5055 - mse: 0.4218\nEpoch 116/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4230 - mae: 0.5077 - mse: 0.4230\nEpoch 117/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4272 - mae: 0.5097 - mse: 0.4272\nEpoch 118/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4254 - mae: 0.5106 - mse: 0.4254\nEpoch 119/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4283 - mae: 0.5115 - mse: 0.4283\nEpoch 120/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4342 - mae: 0.5154 - mse: 0.4342\nEpoch 121/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4313 - mae: 0.5138 - mse: 0.4313\nEpoch 122/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4280 - mae: 0.5108 - mse: 0.4280\nEpoch 123/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4332 - mae: 0.5144 - mse: 0.4332\nEpoch 124/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4284 - mae: 0.5121 - mse: 0.4284\nEpoch 125/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4239 - mae: 0.5091 - mse: 0.4239\nEpoch 126/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4294 - mae: 0.5134 - mse: 0.4294\nEpoch 127/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4329 - mae: 0.5138 - mse: 0.4329\nEpoch 128/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4311 - mae: 0.5116 - mse: 0.4311\nEpoch 129/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4233 - mae: 0.5080 - mse: 0.4233\nEpoch 130/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4425 - mae: 0.5184 - mse: 0.4425\nEpoch 131/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4213 - mae: 0.5075 - mse: 0.4213\nEpoch 132/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4372 - mae: 0.5173 - mse: 0.4372\nEpoch 133/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4183 - mae: 0.5061 - mse: 0.4183\nEpoch 134/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4290 - mae: 0.5106 - mse: 0.4290\nEpoch 135/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4216 - mae: 0.5067 - mse: 0.4216\nEpoch 136/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4219 - mae: 0.5065 - mse: 0.4219\nEpoch 137/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4235 - mae: 0.5089 - mse: 0.4235\nEpoch 138/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4177 - mae: 0.5054 - mse: 0.4177\nEpoch 139/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4238 - mae: 0.5079 - mse: 0.4238\nEpoch 140/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4308 - mae: 0.5129 - mse: 0.4308\nEpoch 141/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4180 - mae: 0.5048 - mse: 0.4180\nEpoch 142/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4214 - mae: 0.5080 - mse: 0.4214\nEpoch 143/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4217 - mae: 0.5065 - mse: 0.4217\nEpoch 144/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4251 - mae: 0.5109 - mse: 0.4251\nEpoch 145/150\n224/224 [==============================] - 1s 4ms/step - loss: 0.4166 - mae: 0.5040 - mse: 0.4166\nEpoch 146/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4210 - mae: 0.5084 - mse: 0.4210\nEpoch 147/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4227 - mae: 0.5083 - mse: 0.4227\nEpoch 148/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4261 - mae: 0.5098 - mse: 0.4261\nEpoch 149/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4194 - mae: 0.5060 - mse: 0.4194\nEpoch 150/150\n224/224 [==============================] - 1s 3ms/step - loss: 0.4186 - mae: 0.5065 - mse: 0.4186\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate_on_train_content = content_hp_model.evaluate(features, target1)\nevaluate_on_train_wording = wording_hp_model.evaluate(features, target2)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:32:58.207752Z","iopub.execute_input":"2023-08-26T09:32:58.208369Z","iopub.status.idle":"2023-08-26T09:32:59.886530Z","shell.execute_reply.started":"2023-08-26T09:32:58.208332Z","shell.execute_reply":"2023-08-26T09:32:59.885628Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"224/224 [==============================] - 1s 2ms/step - loss: 0.2835 - mae: 0.4146 - mse: 0.2835\n224/224 [==============================] - 1s 3ms/step - loss: 0.4140 - mae: 0.5070 - mse: 0.4140\n","output_type":"stream"}]},{"cell_type":"code","source":"print('evaluate_on_train_content', evaluate_on_train_content)\nprint('evaluate_on_train_wording',evaluate_on_train_wording)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:32:59.889481Z","iopub.execute_input":"2023-08-26T09:32:59.889829Z","iopub.status.idle":"2023-08-26T09:32:59.896393Z","shell.execute_reply.started":"2023-08-26T09:32:59.889803Z","shell.execute_reply":"2023-08-26T09:32:59.894606Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"evaluate_on_train_content [0.28349781036376953, 0.4145551323890686, 0.28349781036376953]\nevaluate_on_train_wording [0.41404685378074646, 0.5070337653160095, 0.41404685378074646]\n","output_type":"stream"}]},{"cell_type":"code","source":"content_prediction = content_hp_model.predict(features)\nwording_prediction = wording_hp_model.predict(features)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:32:59.898222Z","iopub.execute_input":"2023-08-26T09:32:59.898983Z","iopub.status.idle":"2023-08-26T09:33:01.215016Z","shell.execute_reply.started":"2023-08-26T09:32:59.898950Z","shell.execute_reply":"2023-08-26T09:33:01.213847Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"224/224 [==============================] - 0s 1ms/step\n224/224 [==============================] - 0s 2ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Predict on test","metadata":{}},{"cell_type":"code","source":"test_pred_content = content_hp_model.predict(features_for_test)\ntest_pred_wording = wording_hp_model.predict(features_for_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:33:01.216826Z","iopub.execute_input":"2023-08-26T09:33:01.217193Z","iopub.status.idle":"2023-08-26T09:33:01.339444Z","shell.execute_reply.started":"2023-08-26T09:33:01.217158Z","shell.execute_reply":"2023-08-26T09:33:01.338376Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## submission","metadata":{}},{"cell_type":"code","source":"test_pred_content = test_pred_content.reshape(-1)\ntest_pred_wording = test_pred_wording.reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:33:01.341183Z","iopub.execute_input":"2023-08-26T09:33:01.341542Z","iopub.status.idle":"2023-08-26T09:33:01.346216Z","shell.execute_reply.started":"2023-08-26T09:33:01.341509Z","shell.execute_reply":"2023-08-26T09:33:01.345084Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'student_id' : test['student_id'],\n    'content' : test_pred_content,\n    'wording' : test_pred_wording\n})","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:33:01.347846Z","iopub.execute_input":"2023-08-26T09:33:01.348501Z","iopub.status.idle":"2023-08-26T09:33:01.360754Z","shell.execute_reply.started":"2023-08-26T09:33:01.348466Z","shell.execute_reply":"2023-08-26T09:33:01.359234Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:33:01.362854Z","iopub.execute_input":"2023-08-26T09:33:01.363451Z","iopub.status.idle":"2023-08-26T09:33:01.381067Z","shell.execute_reply.started":"2023-08-26T09:33:01.363410Z","shell.execute_reply":"2023-08-26T09:33:01.380056Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T09:33:01.385770Z","iopub.execute_input":"2023-08-26T09:33:01.386105Z","iopub.status.idle":"2023-08-26T09:33:01.398346Z","shell.execute_reply.started":"2023-08-26T09:33:01.386079Z","shell.execute_reply":"2023-08-26T09:33:01.397248Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff -1.533198 -1.301491\n1  222222cccccc -1.342265 -1.364608\n2  111111eeeeee -1.517045 -1.435132\n3  333333dddddd -1.427587 -1.395533","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.533198</td>\n      <td>-1.301491</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.342265</td>\n      <td>-1.364608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.517045</td>\n      <td>-1.435132</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.427587</td>\n      <td>-1.395533</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}