{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Goal\n\n<h3 style=\"color:blue\">assess the quality of summaries written by students</h3>\n<h3 style=\"color:indigo\">evaluate how well a student represents the main idea and details of a source text, as well as the clarity, precision, and fluency of the language used in the summary</h3>\n<h3 style=\"color:red\">Freely & publicly available external data is <b>allowed</b>, including pre-trained models</h3>\n<h3>This is Multi-Output problem</h3>","metadata":{}},{"cell_type":"markdown","source":"### Use Hugging Face Library\n### Use NLTK\n### Use Tensorflow","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.212815Z","iopub.execute_input":"2023-08-13T07:41:20.213263Z","iopub.status.idle":"2023-08-13T07:41:20.218583Z","shell.execute_reply.started":"2023-08-13T07:41:20.213227Z","shell.execute_reply":"2023-08-13T07:41:20.217393Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport math\nimport subprocess\nfrom tqdm import tqdm\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.223875Z","iopub.execute_input":"2023-08-13T07:41:20.224309Z","iopub.status.idle":"2023-08-13T07:41:20.234420Z","shell.execute_reply.started":"2023-08-13T07:41:20.224273Z","shell.execute_reply":"2023-08-13T07:41:20.233154Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.237150Z","iopub.execute_input":"2023-08-13T07:41:20.237728Z","iopub.status.idle":"2023-08-13T07:41:20.248832Z","shell.execute_reply.started":"2023-08-13T07:41:20.237673Z","shell.execute_reply":"2023-08-13T07:41:20.247430Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score, median_absolute_error","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.251684Z","iopub.execute_input":"2023-08-13T07:41:20.252184Z","iopub.status.idle":"2023-08-13T07:41:20.264155Z","shell.execute_reply.started":"2023-08-13T07:41:20.252140Z","shell.execute_reply":"2023-08-13T07:41:20.262826Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer, TFBertModel","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.266076Z","iopub.execute_input":"2023-08-13T07:41:20.266489Z","iopub.status.idle":"2023-08-13T07:41:20.277675Z","shell.execute_reply.started":"2023-08-13T07:41:20.266448Z","shell.execute_reply":"2023-08-13T07:41:20.276239Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nsummaries_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\nprompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\nsummaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.280315Z","iopub.execute_input":"2023-08-13T07:41:20.281015Z","iopub.status.idle":"2023-08-13T07:41:20.360607Z","shell.execute_reply.started":"2023-08-13T07:41:20.280975Z","shell.execute_reply":"2023-08-13T07:41:20.359305Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(prompts_train, summaries_train, on='prompt_id')\ntest = pd.merge(prompts_test, summaries_test, on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.363025Z","iopub.execute_input":"2023-08-13T07:41:20.364040Z","iopub.status.idle":"2023-08-13T07:41:20.383308Z","shell.execute_reply.started":"2023-08-13T07:41:20.363987Z","shell.execute_reply":"2023-08-13T07:41:20.382239Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train.rename(columns = {'text' : 'summary'}, inplace=True)\ntest.rename(columns = {'text' : 'summary'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.388246Z","iopub.execute_input":"2023-08-13T07:41:20.388683Z","iopub.status.idle":"2023-08-13T07:41:20.396253Z","shell.execute_reply.started":"2023-08-13T07:41:20.388647Z","shell.execute_reply":"2023-08-13T07:41:20.394833Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.399204Z","iopub.execute_input":"2023-08-13T07:41:20.399593Z","iopub.status.idle":"2023-08-13T07:41:20.421488Z","shell.execute_reply.started":"2023-08-13T07:41:20.399561Z","shell.execute_reply":"2023-08-13T07:41:20.420029Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question prompt_title  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n\n                                         prompt_text    student_id  \\\n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n\n                                             summary   content   wording  \n0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>student_id</th>\n      <th>summary</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>00791789cc1f</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>0086ef22de8f</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n      <td>-0.970237</td>\n      <td>-0.417058</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['summary'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.422943Z","iopub.execute_input":"2023-08-13T07:41:20.423450Z","iopub.status.idle":"2023-08-13T07:41:20.433838Z","shell.execute_reply.started":"2023-08-13T07:41:20.423405Z","shell.execute_reply":"2023-08-13T07:41:20.432665Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"},"metadata":{}}]},{"cell_type":"code","source":"columns_needed = [\"prompt_text\", \"summary\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.435241Z","iopub.execute_input":"2023-08-13T07:41:20.436186Z","iopub.status.idle":"2023-08-13T07:41:20.445003Z","shell.execute_reply.started":"2023-08-13T07:41:20.436136Z","shell.execute_reply":"2023-08-13T07:41:20.444070Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_data = train[columns_needed]","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.446056Z","iopub.execute_input":"2023-08-13T07:41:20.446458Z","iopub.status.idle":"2023-08-13T07:41:20.462434Z","shell.execute_reply.started":"2023-08-13T07:41:20.446424Z","shell.execute_reply":"2023-08-13T07:41:20.460887Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.463729Z","iopub.execute_input":"2023-08-13T07:41:20.464554Z","iopub.status.idle":"2023-08-13T07:41:20.482402Z","shell.execute_reply.started":"2023-08-13T07:41:20.464506Z","shell.execute_reply":"2023-08-13T07:41:20.480939Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                            prompt_text  \\\n0     Chapter 13 \\r\\nAs the sequel to what has alrea...   \n1     Chapter 13 \\r\\nAs the sequel to what has alrea...   \n2     Chapter 13 \\r\\nAs the sequel to what has alrea...   \n3     Chapter 13 \\r\\nAs the sequel to what has alrea...   \n4     Chapter 13 \\r\\nAs the sequel to what has alrea...   \n...                                                 ...   \n7160  With one member trimming beef in a cannery, an...   \n7161  With one member trimming beef in a cannery, an...   \n7162  With one member trimming beef in a cannery, an...   \n7163  With one member trimming beef in a cannery, an...   \n7164  With one member trimming beef in a cannery, an...   \n\n                                                summary  \n0     1 element of an ideal tragedy is that it shoul...  \n1     The three elements of an ideal tragedy are:  H...  \n2     Aristotle states that an ideal tragedy should ...  \n3     One element of an Ideal tragedy is having a co...  \n4     The 3 ideal of tragedy is how complex you need...  \n...                                                 ...  \n7160  In paragraph two, they would use pickle meat a...  \n7161  in the first paragraph  it says \"either can it...  \n7162  They would have piles of filthy meat on the fl...  \n7163  They used all sorts of chemical concoctions to...  \n7164  The meat would smell sour but the would \"rub i...  \n\n[7165 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>1 element of an ideal tragedy is that it shoul...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>The three elements of an ideal tragedy are:  H...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>Aristotle states that an ideal tragedy should ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>One element of an Ideal tragedy is having a co...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n      <td>The 3 ideal of tragedy is how complex you need...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>In paragraph two, they would use pickle meat a...</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>in the first paragraph  it says \"either can it...</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>They would have piles of filthy meat on the fl...</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>They used all sorts of chemical concoctions to...</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>With one member trimming beef in a cannery, an...</td>\n      <td>The meat would smell sour but the would \"rub i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#from transformers import XLNetTokenizer, TFXLNetModel\n#tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n#model = TFXLNetModel.from_pretrained('xlnet-base-cased', return_dict=True)\n\n#from transformers import RobertaTokenizer, TFRobertaModel\n#tokenizer = RobertaTokenizer.from_pretrained('roberta-base-cased')\n#model = TFRobertaModel.from_pretrained('roberta-base-cased', return_dict=True)\n\nfrom transformers import AutoTokenizer, TFBertModel\nmodel = TFBertModel.from_pretrained('bert-base-uncased')\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:20.486332Z","iopub.execute_input":"2023-08-13T07:41:20.487189Z","iopub.status.idle":"2023-08-13T07:41:24.231777Z","shell.execute_reply.started":"2023-08-13T07:41:20.487149Z","shell.execute_reply":"2023-08-13T07:41:24.230739Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Next time use prepare_tf_dataset which is used to directly tokenize and data colat and\n### make dataset compatible with tensorflow\n####       https://huggingface.co/docs/transformers/v4.31.0/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset","metadata":{}},{"cell_type":"code","source":"\ndef vectorize_dataframe(dataframe, col):\n    vectors = []\n    for text in tqdm(dataframe[col].tolist()):\n        text_tokens = tokenizer(text, return_tensors=\"tf\", padding='max_length', truncation=True)\n        \n        output = model(text_tokens)\n        \n        pooler_output = output.pooler_output\n\n        \n        vectors.append(pooler_output)\n    return vectors\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:24.235772Z","iopub.execute_input":"2023-08-13T07:41:24.236156Z","iopub.status.idle":"2023-08-13T07:41:24.243399Z","shell.execute_reply.started":"2023-08-13T07:41:24.236122Z","shell.execute_reply":"2023-08-13T07:41:24.242300Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\n#with open(\"BERT_prompt_text_embeddings.pkl\", \"wb\") as file:\n#    pickle.dump(train_data['prompt_text_embeddings'], file)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:24.246313Z","iopub.execute_input":"2023-08-13T07:41:24.246691Z","iopub.status.idle":"2023-08-13T07:41:24.260384Z","shell.execute_reply.started":"2023-08-13T07:41:24.246660Z","shell.execute_reply":"2023-08-13T07:41:24.257789Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/embeddings/BERT_prompt_text_embeddings.pkl\", \"rb\") as file:\n    train_data['prompt_text_embedded'] = pickle.load(file)\n    \nwith open(\"/kaggle/input/embeddings/BERT_summary_embeddings.pkl\", \"rb\") as file:\n    train_data['summary_embedded'] = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:24.261705Z","iopub.execute_input":"2023-08-13T07:41:24.262078Z","iopub.status.idle":"2023-08-13T07:41:24.877460Z","shell.execute_reply.started":"2023-08-13T07:41:24.262043Z","shell.execute_reply":"2023-08-13T07:41:24.876454Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"traning_set = train_data[['prompt_text_embedded', 'summary_embedded']]","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:24.879057Z","iopub.execute_input":"2023-08-13T07:41:24.880017Z","iopub.status.idle":"2023-08-13T07:41:24.887625Z","shell.execute_reply.started":"2023-08-13T07:41:24.879981Z","shell.execute_reply":"2023-08-13T07:41:24.886415Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"traning_set","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:24.889201Z","iopub.execute_input":"2023-08-13T07:41:24.889756Z","iopub.status.idle":"2023-08-13T07:41:26.223356Z","shell.execute_reply.started":"2023-08-13T07:41:24.889717Z","shell.execute_reply":"2023-08-13T07:41:26.222150Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                                   prompt_text_embedded  \\\n0     ((tf.Tensor(-0.28394255, shape=(), dtype=float...   \n1     ((tf.Tensor(-0.28394255, shape=(), dtype=float...   \n2     ((tf.Tensor(-0.28394255, shape=(), dtype=float...   \n3     ((tf.Tensor(-0.28394255, shape=(), dtype=float...   \n4     ((tf.Tensor(-0.28394255, shape=(), dtype=float...   \n...                                                 ...   \n7160  ((tf.Tensor(-0.6679727, shape=(), dtype=float3...   \n7161  ((tf.Tensor(-0.6679727, shape=(), dtype=float3...   \n7162  ((tf.Tensor(-0.6679727, shape=(), dtype=float3...   \n7163  ((tf.Tensor(-0.6679727, shape=(), dtype=float3...   \n7164  ((tf.Tensor(-0.6679727, shape=(), dtype=float3...   \n\n                                       summary_embedded  \n0     ((tf.Tensor(-0.8216937, shape=(), dtype=float3...  \n1     ((tf.Tensor(-0.83174103, shape=(), dtype=float...  \n2     ((tf.Tensor(-0.5781112, shape=(), dtype=float3...  \n3     ((tf.Tensor(-0.82676977, shape=(), dtype=float...  \n4     ((tf.Tensor(-0.6173656, shape=(), dtype=float3...  \n...                                                 ...  \n7160  ((tf.Tensor(-0.45960867, shape=(), dtype=float...  \n7161  ((tf.Tensor(-0.77414584, shape=(), dtype=float...  \n7162  ((tf.Tensor(-0.5644295, shape=(), dtype=float3...  \n7163  ((tf.Tensor(-0.6844212, shape=(), dtype=float3...  \n7164  ((tf.Tensor(-0.6500841, shape=(), dtype=float3...  \n\n[7165 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_text_embedded</th>\n      <th>summary_embedded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>((tf.Tensor(-0.28394255, shape=(), dtype=float...</td>\n      <td>((tf.Tensor(-0.8216937, shape=(), dtype=float3...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>((tf.Tensor(-0.28394255, shape=(), dtype=float...</td>\n      <td>((tf.Tensor(-0.83174103, shape=(), dtype=float...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>((tf.Tensor(-0.28394255, shape=(), dtype=float...</td>\n      <td>((tf.Tensor(-0.5781112, shape=(), dtype=float3...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>((tf.Tensor(-0.28394255, shape=(), dtype=float...</td>\n      <td>((tf.Tensor(-0.82676977, shape=(), dtype=float...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>((tf.Tensor(-0.28394255, shape=(), dtype=float...</td>\n      <td>((tf.Tensor(-0.6173656, shape=(), dtype=float3...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7160</th>\n      <td>((tf.Tensor(-0.6679727, shape=(), dtype=float3...</td>\n      <td>((tf.Tensor(-0.45960867, shape=(), dtype=float...</td>\n    </tr>\n    <tr>\n      <th>7161</th>\n      <td>((tf.Tensor(-0.6679727, shape=(), dtype=float3...</td>\n      <td>((tf.Tensor(-0.77414584, shape=(), dtype=float...</td>\n    </tr>\n    <tr>\n      <th>7162</th>\n      <td>((tf.Tensor(-0.6679727, shape=(), dtype=float3...</td>\n      <td>((tf.Tensor(-0.5644295, shape=(), dtype=float3...</td>\n    </tr>\n    <tr>\n      <th>7163</th>\n      <td>((tf.Tensor(-0.6679727, shape=(), dtype=float3...</td>\n      <td>((tf.Tensor(-0.6844212, shape=(), dtype=float3...</td>\n    </tr>\n    <tr>\n      <th>7164</th>\n      <td>((tf.Tensor(-0.6679727, shape=(), dtype=float3...</td>\n      <td>((tf.Tensor(-0.6500841, shape=(), dtype=float3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7165 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndef convert_tensor_to_numpy(tensor):\n        return np.array(tensor, dtype='float32')\n\ntraning_set = traning_set.applymap(convert_tensor_to_numpy)\ntarget = np.array(train['content'] )","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.224751Z","iopub.execute_input":"2023-08-13T07:41:26.225121Z","iopub.status.idle":"2023-08-13T07:41:26.317574Z","shell.execute_reply.started":"2023-08-13T07:41:26.225088Z","shell.execute_reply":"2023-08-13T07:41:26.316281Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Take average of embeddings  [Not required, just checking]","metadata":{}},{"cell_type":"code","source":"\"\"\"\ndef average(column) :\n    for index, value in enumerate(column) :\n        column[index] = np.sum(value)\n        \n    return column\n\ntraning_set['summary_embedded'] = average(traning_set['summary_embedded'])\ntraning_set['prompt_text_embedded'] = average(traning_set['prompt_text_embedded'])\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.319081Z","iopub.execute_input":"2023-08-13T07:41:26.319452Z","iopub.status.idle":"2023-08-13T07:41:26.325808Z","shell.execute_reply.started":"2023-08-13T07:41:26.319421Z","shell.execute_reply":"2023-08-13T07:41:26.324853Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"\"\\ndef average(column) :\\n    for index, value in enumerate(column) :\\n        column[index] = np.sum(value)\\n        \\n    return column\\n\\ntraning_set['summary_embedded'] = average(traning_set['summary_embedded'])\\ntraning_set['prompt_text_embedded'] = average(traning_set['prompt_text_embedded'])\\n\\n\""},"metadata":{}}]},{"cell_type":"code","source":"#traning_set['summary_embedded'] = np.array( traning_set['summary_embedded'])\n#traning_set['prompt_text_embedded'] = np.array( traning_set['prompt_text_embedded'])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.327114Z","iopub.execute_input":"2023-08-13T07:41:26.328158Z","iopub.status.idle":"2023-08-13T07:41:26.338480Z","shell.execute_reply.started":"2023-08-13T07:41:26.328124Z","shell.execute_reply":"2023-08-13T07:41:26.337256Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"target = np.array(train['content'])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.339743Z","iopub.execute_input":"2023-08-13T07:41:26.340092Z","iopub.status.idle":"2023-08-13T07:41:26.355448Z","shell.execute_reply.started":"2023-08-13T07:41:26.340062Z","shell.execute_reply":"2023-08-13T07:41:26.353933Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(traning_set, target, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.357151Z","iopub.execute_input":"2023-08-13T07:41:26.357642Z","iopub.status.idle":"2023-08-13T07:41:26.371913Z","shell.execute_reply.started":"2023-08-13T07:41:26.357597Z","shell.execute_reply":"2023-08-13T07:41:26.370603Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.375193Z","iopub.execute_input":"2023-08-13T07:41:26.376224Z","iopub.status.idle":"2023-08-13T07:41:26.393200Z","shell.execute_reply.started":"2023-08-13T07:41:26.376176Z","shell.execute_reply":"2023-08-13T07:41:26.391910Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Train your model using model.fit()\nmodel.fit(X_train, y_train, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T07:41:26.394234Z","iopub.execute_input":"2023-08-13T07:41:26.394594Z","iopub.status.idle":"2023-08-13T07:41:26.529175Z","shell.execute_reply.started":"2023-08-13T07:41:26.394564Z","shell.execute_reply":"2023-08-13T07:41:26.527465Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train your model using model.fit()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."],"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}